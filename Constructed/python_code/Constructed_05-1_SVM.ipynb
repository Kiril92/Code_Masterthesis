{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import shape\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "import random\n",
    "import math\n",
    "import dill\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "# from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import device\n",
    "\n",
    "# Tensorflow soll auf CPU und nicht auf der GPU laufen\n",
    "device(\"cpu:0\")\n",
    "# f√ºr GPU:\n",
    "# tf.device(\"gpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f4cfebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../../rna/_functions/functions.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3c67a",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90cb3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_data_combined = \"../data/combined_data/constructed_images_combined_60_2022_08_25.csv\"\n",
    "filepath_labels = \"../data/combined_data/constructed_labels_60_2022_08_25.csv\"\n",
    "\n",
    "X = np.genfromtxt(filepath_data_combined, delimiter = \",\")\n",
    "y = np.array(pd.read_csv(filepath_labels, header=None))\n",
    "\n",
    "# Factorize into dichotomous variable\n",
    "Y = pd.factorize(y[:, 0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d954d8",
   "metadata": {},
   "source": [
    "### Load Persistences Landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d4eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_folderpath = \"../data/persistence_landscapes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6f815523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Eingelesenen Dateien\n",
    "# print(glob.glob(pl_folderpath + \"avgPL_bucket01_H0_scaledWithin*.pkl\")[-1])\n",
    "# print(glob.glob(pl_folderpath + \"avgPL_bucket01_H1_scaledWithin*.pkl\")[-1])\n",
    "# print(glob.glob(pl_folderpath + \"avgPL_bucket01_H0_scaledBetween*.pkl\")[-1])\n",
    "# print(glob.glob(pl_folderpath + \"avgPL_bucket01_H1_scaledBetween*.pkl\")[-1])\n",
    "# print(glob.glob(pl_folderpath + \"avgPL_bucket01_H0_unscaled*.pkl\")[-1])\n",
    "# print(glob.glob(pl_folderpath + \"avgPL_bucket01_H1_unscaled*.pkl\")[-1])\n",
    "\n",
    "avgPL_bucket01_H0_scaledWithin = load_file(file = glob.glob(pl_folderpath + \"PL_H0_scaledWithin*.pkl\")[-1])\n",
    "avgPL_bucket01_H1_scaledWithin = load_file(file = glob.glob(pl_folderpath + \"PL_H1_scaledWithin*.pkl\")[-1])\n",
    "\n",
    "avgPL_bucket01_H0_scaledBetween = load_file(file = glob.glob(pl_folderpath + \"PL_H0_scaledBetween*.pkl\")[-1])\n",
    "avgPL_bucket01_H1_scaledBetween = load_file(file = glob.glob(pl_folderpath + \"PL_H1_scaledBetween*.pkl\")[-1])\n",
    "\n",
    "avgPL_bucket01_H0_unscaled = load_file(file = glob.glob(pl_folderpath + \"PL_H0_unscaled*.pkl\")[-1])\n",
    "avgPL_bucket01_H1_unscaled = load_file(file = glob.glob(pl_folderpath + \"PL_H1_unscaled*.pkl\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a06ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter for persistence landscapes\n",
    "pl_resolution = 200\n",
    "pl_num_landscapes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989417d2",
   "metadata": {},
   "source": [
    "### Train-Test-Splits Persistence Landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "afa49d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket01 scaledBetween\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledBetween_H0_train, X_b01_scaledBetween_H0_test, Y_b01_scaledBetween_H0_train, Y_b01_scaledBetween_H0_test = train_test_split(avgPL_bucket01_H0_scaledBetween,\n",
    "                                                                                                                                        Y,\n",
    "                                                                                                                                        test_size=0.2)\n",
    "\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledBetween_H1_train, X_b01_scaledBetween_H1_test, Y_b01_scaledBetween_H1_train, Y_b01_scaledBetween_H1_test = train_test_split(avgPL_bucket01_H1_scaledBetween,\n",
    "                                                                                                                                        Y,\n",
    "                                                                                                                                        test_size=0.2)\n",
    "\n",
    "# Bucket01 scaledWithin\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledWithin_H0_train, X_b01_scaledWithin_H0_test, Y_b01_scaledWithin_H0_train, Y_b01_scaledWithin_H0_test = train_test_split(avgPL_bucket01_H0_scaledWithin,\n",
    "                                                                                                                                    Y,\n",
    "                                                                                                                                    test_size=0.2)\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledWithin_H1_train, X_b01_scaledWithin_H1_test, Y_b01_scaledWithin_H1_train, Y_b01_scaledWithin_H1_test = train_test_split(avgPL_bucket01_H1_scaledWithin,\n",
    "                                                                                                                                    Y,\n",
    "                                                                                                                                    test_size=0.2)\n",
    "\n",
    "# Bucket01 Unscaled\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_unscaled_H0_train, X_b01_unscaled_H0_test, Y_b01_unscaled_H0_train, Y_b01_unscaled_H0_test = train_test_split(avgPL_bucket01_H0_unscaled,\n",
    "                                                                                                                    Y,\n",
    "                                                                                                                    test_size=0.2)\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_unscaled_H1_train, X_b01_unscaled_H1_test, Y_b01_unscaled_H1_train, Y_b01_unscaled_H1_test = train_test_split(avgPL_bucket01_H1_unscaled,\n",
    "                                                                                                                    Y,\n",
    "                                                                                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f34a2",
   "metadata": {},
   "source": [
    "# Machine Learning Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c7971",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c467efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath_results = \"../results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf809d85",
   "metadata": {},
   "source": [
    "### Train-Test-Split raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f516e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split with data in vector format\n",
    "image_vector_size = 6*6\n",
    "\n",
    "X_raw_train, X_raw_test, y_raw_train, y_raw_test = train_test_split(X.reshape(len(X), image_vector_size),\n",
    "                                                                    np.asarray(y),\n",
    "                                                                    test_size = 0.3,\n",
    "                                                                    random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e7823",
   "metadata": {},
   "source": [
    "##### SVM (raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2bd44915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on raw data: 1.0\n",
      "Confusion-Matrix:\n",
      " [[10  0]\n",
      " [ 0  8]] \n",
      " \n",
      "True Negative:  10 \n",
      "True Positive 8 \n",
      "False Negative 0 \n",
      "False Positive 0\n",
      "\n",
      "TPR: 1.0 \n",
      "TNR:  1.0\n",
      "\n",
      "Accuracy: 1.0\n",
      "F1 (micro): 1.0\n",
      "F1 (macro): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Linear - Rawdata\n",
    "clf = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_raw_train, y_raw_train.ravel())\n",
    "\n",
    "print(\"Accuracy SVM on raw data: \" + str(clf.score(X_raw_test, y_raw_test))[:10])\n",
    "\n",
    "evaluation(y_test = y_raw_test,\n",
    "           y_pred = clf.predict(X_raw_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_rawdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8a1a0f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on raw data: 1.0\n",
      "Confusion-Matrix:\n",
      " [[10  0]\n",
      " [ 0  8]] \n",
      " \n",
      "True Negative:  10 \n",
      "True Positive 8 \n",
      "False Negative 0 \n",
      "False Positive 0\n",
      "\n",
      "TPR: 1.0 \n",
      "TNR:  1.0\n",
      "\n",
      "Accuracy: 1.0\n",
      "F1 (micro): 1.0\n",
      "F1 (macro): 1.0\n"
     ]
    }
   ],
   "source": [
    "# RBF - Rawdata\n",
    "clf = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_raw_train, y_raw_train.ravel())\n",
    "\n",
    "print(\"Accuracy SVM on raw data: \" + str(clf.score(X_raw_test, y_raw_test))[:10])\n",
    "\n",
    "evaluation(y_test = y_raw_test,\n",
    "           y_pred = clf.predict(X_raw_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_rawdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf41392",
   "metadata": {},
   "source": [
    "##### SVM (Persistent Landscapes  - scaledWithin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e5622361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.75\n",
      "Confusion-Matrix:\n",
      " [[3 2]\n",
      " [1 6]] \n",
      " \n",
      "True Negative:  3 \n",
      "True Positive 6 \n",
      "False Negative 1 \n",
      "False Positive 2\n",
      "\n",
      "TPR: 0.8571428571428571 \n",
      "TNR:  0.6\n",
      "\n",
      "Accuracy: 0.75\n",
      "F1 (micro): 0.75\n",
      "F1 (macro): 0.7333333333333332\n"
     ]
    }
   ],
   "source": [
    "# Linear - H0 - scaledWithin\n",
    "clf_pl_h0 = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='linear')).fit(X_b01_scaledWithin_H0_train, Y_b01_scaledWithin_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl_h0.score(X_b01_scaledWithin_H0_test, Y_b01_scaledWithin_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H0_test,\n",
    "           y_pred = clf_pl_h0.predict(X_b01_scaledWithin_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H0_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0b260123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.75\n",
      "Confusion-Matrix:\n",
      " [[6 3]\n",
      " [0 3]] \n",
      " \n",
      "True Negative:  6 \n",
      "True Positive 3 \n",
      "False Negative 0 \n",
      "False Positive 3\n",
      "\n",
      "TPR: 1.0 \n",
      "TNR:  0.6666666666666666\n",
      "\n",
      "Accuracy: 0.75\n",
      "F1 (micro): 0.75\n",
      "F1 (macro): 0.7333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Linear - H1 - scaledWithin\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='linear')).fit(X_b01_scaledWithin_H1_train, Y_b01_scaledWithin_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl.score(X_b01_scaledWithin_H1_test, Y_b01_scaledWithin_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H1_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledWithin_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H1_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ce43da9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.75\n",
      "Confusion-Matrix:\n",
      " [[3 2]\n",
      " [1 6]] \n",
      " \n",
      "True Negative:  3 \n",
      "True Positive 6 \n",
      "False Negative 1 \n",
      "False Positive 2\n",
      "\n",
      "TPR: 0.8571428571428571 \n",
      "TNR:  0.6\n",
      "\n",
      "Accuracy: 0.75\n",
      "F1 (micro): 0.75\n",
      "F1 (macro): 0.7333333333333332\n"
     ]
    }
   ],
   "source": [
    "# RBF - H0 - scaledWithin\n",
    "clf_pl_h0 = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='rbf')).fit(X_b01_scaledWithin_H0_train, Y_b01_scaledWithin_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl_h0.score(X_b01_scaledWithin_H0_test, Y_b01_scaledWithin_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H0_test,\n",
    "           y_pred = clf_pl_h0.predict(X_b01_scaledWithin_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H0_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3d8d8cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.83333333\n",
      "Confusion-Matrix:\n",
      " [[8 1]\n",
      " [1 2]] \n",
      " \n",
      "True Negative:  8 \n",
      "True Positive 2 \n",
      "False Negative 1 \n",
      "False Positive 1\n",
      "\n",
      "TPR: 0.6666666666666666 \n",
      "TNR:  0.8888888888888888\n",
      "\n",
      "Accuracy: 0.8333333333333334\n",
      "F1 (micro): 0.8333333333333334\n",
      "F1 (macro): 0.7777777777777777\n"
     ]
    }
   ],
   "source": [
    "# RBF - H1 - scaledWithin\n",
    "clf_pl_rbf = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='rbf')).fit(X_b01_scaledWithin_H1_train, Y_b01_scaledWithin_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl_rbf.score(X_b01_scaledWithin_H1_test, Y_b01_scaledWithin_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H1_test,\n",
    "           y_pred = clf_pl_rbf.predict(X_b01_scaledWithin_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H1_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343bb3f8",
   "metadata": {},
   "source": [
    "##### SVM (Persistent Landscapes - scaledBetween)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b9edbf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.58333333\n",
      "Confusion-Matrix:\n",
      " [[5 2]\n",
      " [3 2]] \n",
      " \n",
      "True Negative:  5 \n",
      "True Positive 2 \n",
      "False Negative 3 \n",
      "False Positive 2\n",
      "\n",
      "TPR: 0.4 \n",
      "TNR:  0.7142857142857143\n",
      "\n",
      "Accuracy: 0.5833333333333334\n",
      "F1 (micro): 0.5833333333333334\n",
      "F1 (macro): 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Linear - H0 - scaledBetween\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_b01_scaledBetween_H0_train, Y_b01_scaledBetween_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_scaledBetween_H0_test, Y_b01_scaledBetween_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H0_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledBetween_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H0_scaledBetween.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5d2556a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.91666666\n",
      "Confusion-Matrix:\n",
      " [[6 0]\n",
      " [1 5]] \n",
      " \n",
      "True Negative:  6 \n",
      "True Positive 5 \n",
      "False Negative 1 \n",
      "False Positive 0\n",
      "\n",
      "TPR: 0.8333333333333334 \n",
      "TNR:  1.0\n",
      "\n",
      "Accuracy: 0.9166666666666666\n",
      "F1 (micro): 0.9166666666666666\n",
      "F1 (macro): 0.916083916083916\n"
     ]
    }
   ],
   "source": [
    "# Linear - H1 - scaledBetween\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_b01_scaledBetween_H1_train, Y_b01_scaledBetween_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_scaledBetween_H1_test, Y_b01_scaledBetween_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H1_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledBetween_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H1_scaledBetween.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d15ab6a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.91666666\n",
      "Confusion-Matrix:\n",
      " [[6 1]\n",
      " [0 5]] \n",
      " \n",
      "True Negative:  6 \n",
      "True Positive 5 \n",
      "False Negative 0 \n",
      "False Positive 1\n",
      "\n",
      "TPR: 1.0 \n",
      "TNR:  0.8571428571428571\n",
      "\n",
      "Accuracy: 0.9166666666666666\n",
      "F1 (micro): 0.9166666666666666\n",
      "F1 (macro): 0.916083916083916\n"
     ]
    }
   ],
   "source": [
    "# RBF - H0 - scaledBetween\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_b01_scaledBetween_H0_train, Y_b01_scaledBetween_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_scaledBetween_H0_test, Y_b01_scaledBetween_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H0_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledBetween_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H0_scaledBetween.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b388c581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.83333333\n",
      "Confusion-Matrix:\n",
      " [[4 2]\n",
      " [0 6]] \n",
      " \n",
      "True Negative:  4 \n",
      "True Positive 6 \n",
      "False Negative 0 \n",
      "False Positive 2\n",
      "\n",
      "TPR: 1.0 \n",
      "TNR:  0.6666666666666666\n",
      "\n",
      "Accuracy: 0.8333333333333334\n",
      "F1 (micro): 0.8333333333333334\n",
      "F1 (macro): 0.8285714285714285\n"
     ]
    }
   ],
   "source": [
    "# RBF - H1 - scaledBetween\n",
    "clf_pl_rbf = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_b01_scaledBetween_H1_train, Y_b01_scaledBetween_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl_rbf.score(X_b01_scaledBetween_H1_test, Y_b01_scaledBetween_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H1_test,\n",
    "           y_pred = clf_pl_rbf.predict(X_b01_scaledBetween_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H1_scaledBetween.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
