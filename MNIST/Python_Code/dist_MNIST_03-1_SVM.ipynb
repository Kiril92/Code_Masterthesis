{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28f5774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x7f49ec38f4c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import shape\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "import random\n",
    "import math\n",
    "import dill\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "# from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from random import seed\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import device\n",
    "\n",
    "# Tensorflow soll auf CPU und nicht auf der GPU laufen\n",
    "device(\"cpu:0\")\n",
    "\n",
    "# f√ºr GPU:\n",
    "# tf.device(\"gpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cfebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '/home/jovyan/rna/_functions/functions.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3c67a",
   "metadata": {},
   "source": [
    "### Load MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553a399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MNIST von sklearn mit 28x28 Pixel\n",
    "# from sklearn.datasets import fetch_openml\n",
    "\n",
    "# # Load data from https://www.openml.org/d/554\n",
    "# X_raw, y_raw = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90cb3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data that was saved on this system\n",
    "\n",
    "raw_data = load_file(file = \"/home/jovyan/rna/MNIST/Raw_Data/MNIST_images.pkl\")\n",
    "X_raw = raw_data[0]\n",
    "y_raw = raw_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51fb9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on indices of '0' and '8'\n",
    "indices = (y_raw == '0') | (y_raw == '8')\n",
    "\n",
    "# Reshape into squares\n",
    "X_raw = X_raw[indices, :]\n",
    "X = X_raw.reshape([sum(indices), 28, 28])\n",
    "\n",
    "y = y_raw[indices]\n",
    "\n",
    "# Factorize into dichotomous variable\n",
    "Y = pd.factorize(y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4016fa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '8'], dtype=object), array([1032,  966]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We analyse 1998 samples\n",
    "np.unique(y[0:1998], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d954d8",
   "metadata": {},
   "source": [
    "### Load Persistences Landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d4eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_folderpath = \"/home/jovyan/rna/MNIST/persistence_landscapes_averages/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bba26de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/rna/MNIST/persistence_landscapes_averages/avgPL_bucket01_H0_scaledWithin_2022-09-06.pkl\n",
      "/home/jovyan/rna/MNIST/persistence_landscapes_averages/avgPL_bucket01_H1_scaledWithin_2022-09-06.pkl\n",
      "/home/jovyan/rna/MNIST/persistence_landscapes_averages/avgPL_bucket01_H0_scaledBetween_2022-09-06.pkl\n",
      "/home/jovyan/rna/MNIST/persistence_landscapes_averages/avgPL_bucket01_H1_scaledBetween_2022-09-06.pkl\n",
      "/home/jovyan/rna/MNIST/persistence_landscapes_averages/avgPL_bucket01_H0_unscaled_2022-09-06.pkl\n",
      "/home/jovyan/rna/MNIST/persistence_landscapes_averages/avgPL_bucket01_H1_unscaled_2022-09-06.pkl\n"
     ]
    }
   ],
   "source": [
    "# Eingelesenen Dateien\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H0_scaledWithin*.pkl\")[-1])\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H1_scaledWithin*.pkl\")[-1])\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H0_scaledBetween*.pkl\")[-1])\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H1_scaledBetween*.pkl\")[-1])\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H0_unscaled*.pkl\")[-1])\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H1_unscaled*.pkl\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f815523",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgPL_bucket01_H0_scaledWithin = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H0_scaledWithin*.pkl\")[-1])\n",
    "avgPL_bucket01_H1_scaledWithin = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H1_scaledWithin*.pkl\")[-1])\n",
    "\n",
    "avgPL_bucket01_H0_scaledBetween = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H0_scaledBetween*.pkl\")[-1])\n",
    "avgPL_bucket01_H1_scaledBetween = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H1_scaledBetween*.pkl\")[-1])\n",
    "\n",
    "avgPL_bucket01_H0_unscaled = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H0_unscaled*.pkl\")[-1])\n",
    "avgPL_bucket01_H1_unscaled = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H1_unscaled*.pkl\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a06ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter for persistence landscapes\n",
    "pl_resolution = 250\n",
    "pl_num_landscapes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989417d2",
   "metadata": {},
   "source": [
    "### Train-Test-Splits Persistence Landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92e20091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1998"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_samples = len(avgPL_bucket01_H0_scaledBetween)\n",
    "relevant_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afa49d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket01 scaledBetween\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledBetween_H0_train, X_b01_scaledBetween_H0_test, Y_b01_scaledBetween_H0_train, Y_b01_scaledBetween_H0_test = train_test_split(avgPL_bucket01_H0_scaledBetween,\n",
    "                                                                                                                                        Y[0:relevant_samples],\n",
    "                                                                                                                                        test_size=0.2)\n",
    "\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledBetween_H1_train, X_b01_scaledBetween_H1_test, Y_b01_scaledBetween_H1_train, Y_b01_scaledBetween_H1_test = train_test_split(avgPL_bucket01_H1_scaledBetween,\n",
    "                                                                                                                                        Y[0:relevant_samples],\n",
    "                                                                                                                                        test_size=0.2)\n",
    "\n",
    "# Bucket01 scaledWithin\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledWithin_H0_train, X_b01_scaledWithin_H0_test, Y_b01_scaledWithin_H0_train, Y_b01_scaledWithin_H0_test = train_test_split(avgPL_bucket01_H0_scaledWithin,\n",
    "                                                                                                                                    Y[0:relevant_samples],\n",
    "                                                                                                                                    test_size=0.2)\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledWithin_H1_train, X_b01_scaledWithin_H1_test, Y_b01_scaledWithin_H1_train, Y_b01_scaledWithin_H1_test = train_test_split(avgPL_bucket01_H1_scaledWithin,\n",
    "                                                                                                                                    Y[0:relevant_samples],\n",
    "                                                                                                                                    test_size=0.2)\n",
    "\n",
    "# Bucket01 Unscaled\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_unscaled_H0_train, X_b01_unscaled_H0_test, Y_b01_unscaled_H0_train, Y_b01_unscaled_H0_test = train_test_split(avgPL_bucket01_H0_unscaled,\n",
    "                                                                                                                    Y[0:relevant_samples],\n",
    "                                                                                                                    test_size=0.2)\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_unscaled_H1_train, X_b01_unscaled_H1_test, Y_b01_unscaled_H1_train, Y_b01_unscaled_H1_test = train_test_split(avgPL_bucket01_H1_unscaled,\n",
    "                                                                                                                    Y[0:relevant_samples],\n",
    "                                                                                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f34a2",
   "metadata": {},
   "source": [
    "# Machine Learning Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c7971",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c467efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb81d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath_results = \"/home/jovyan/rna/MNIST/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f516e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split with data in vector format\n",
    "image_vector_size = 28*28\n",
    "\n",
    "X_raw_train, X_raw_test, y_raw_train, y_raw_test = train_test_split(X[0:len(avgPL_bucket01_H1_scaledBetween)].reshape(len(avgPL_bucket01_H1_scaledBetween), image_vector_size),\n",
    "                                                                    np.asarray(y[0:len(avgPL_bucket01_H1_scaledBetween)]),\n",
    "                                                                    test_size = 0.3,\n",
    "                                                                    random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e7823",
   "metadata": {},
   "source": [
    "##### SVM (raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bd44915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on raw data: 0.98166666\n",
      "Confusion-Matrix:\n",
      " [[312   5]\n",
      " [  6 277]] \n",
      " \n",
      "True Negative:  312 \n",
      "True Positive 277 \n",
      "False Negative 6 \n",
      "False Positive 5\n",
      "\n",
      "TPR: 0.9787985865724381 \n",
      "TNR:  0.9842271293375394\n",
      "\n",
      "Accuracy: 0.9816666666666667\n",
      "F1 (micro): 0.9816666666666667\n",
      "F1 (macro): 0.981604069402829\n"
     ]
    }
   ],
   "source": [
    "# Linear - Rawdata\n",
    "clf = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_raw_train, y_raw_train.ravel())\n",
    "\n",
    "print(\"Accuracy SVM on raw data: \" + str(clf.score(X_raw_test, y_raw_test))[:10])\n",
    "\n",
    "evaluation(y_test = y_raw_test,\n",
    "           y_pred = clf.predict(X_raw_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_rawdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b85ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on raw data: 0.98833333\n",
      "Confusion-Matrix:\n",
      " [[310   7]\n",
      " [  0 283]] \n",
      " \n",
      "True Negative:  310 \n",
      "True Positive 283 \n",
      "False Negative 0 \n",
      "False Positive 7\n",
      "\n",
      "TPR: 1.0 \n",
      "TNR:  0.9779179810725552\n",
      "\n",
      "Accuracy: 0.9883333333333333\n",
      "F1 (micro): 0.9883333333333333\n",
      "F1 (macro): 0.9883096603956345\n"
     ]
    }
   ],
   "source": [
    "# RBF - Rawdata\n",
    "clf = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_raw_train, y_raw_train.ravel())\n",
    "\n",
    "print(\"Accuracy SVM on raw data: \" + str(clf.score(X_raw_test, y_raw_test))[:10])\n",
    "\n",
    "evaluation(y_test = y_raw_test,\n",
    "           y_pred = clf.predict(X_raw_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_rawdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf41392",
   "metadata": {},
   "source": [
    "##### SVM (Persistent Landscapes - scaledWithin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b260123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.5675\n",
      "Confusion-Matrix:\n",
      " [[132  80]\n",
      " [ 93  95]] \n",
      " \n",
      "True Negative:  132 \n",
      "True Positive 95 \n",
      "False Negative 93 \n",
      "False Positive 80\n",
      "\n",
      "TPR: 0.5053191489361702 \n",
      "TNR:  0.6226415094339622\n",
      "\n",
      "Accuracy: 0.5675\n",
      "F1 (micro): 0.5675\n",
      "F1 (macro): 0.563767485548222\n"
     ]
    }
   ],
   "source": [
    "# Linear - H0 - scaledWithin\n",
    "clf_pl_h0 = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='linear')).fit(X_b01_scaledWithin_H0_train, Y_b01_scaledWithin_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl_h0.score(X_b01_scaledWithin_H0_test, Y_b01_scaledWithin_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H0_test,\n",
    "           y_pred = clf_pl_h0.predict(X_b01_scaledWithin_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H0_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "116d83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.46\n",
      "Confusion-Matrix:\n",
      " [[ 82 121]\n",
      " [ 95 102]] \n",
      " \n",
      "True Negative:  82 \n",
      "True Positive 102 \n",
      "False Negative 95 \n",
      "False Positive 121\n",
      "\n",
      "TPR: 0.5177664974619289 \n",
      "TNR:  0.4039408866995074\n",
      "\n",
      "Accuracy: 0.46\n",
      "F1 (micro): 0.46\n",
      "F1 (macro): 0.4586466165413534\n"
     ]
    }
   ],
   "source": [
    "# Linear - H1 - scaledWithin\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='linear')).fit(X_b01_scaledWithin_H1_train, Y_b01_scaledWithin_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl.score(X_b01_scaledWithin_H1_test, Y_b01_scaledWithin_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H1_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledWithin_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H1_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6d94b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.575\n",
      "Confusion-Matrix:\n",
      " [[171  41]\n",
      " [129  59]] \n",
      " \n",
      "True Negative:  171 \n",
      "True Positive 59 \n",
      "False Negative 129 \n",
      "False Positive 41\n",
      "\n",
      "TPR: 0.31382978723404253 \n",
      "TNR:  0.8066037735849056\n",
      "\n",
      "Accuracy: 0.575\n",
      "F1 (micro): 0.575\n",
      "F1 (macro): 0.538845486111111\n"
     ]
    }
   ],
   "source": [
    "# RBF - H0 - scaledWithin\n",
    "clf_pl_h0 = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='rbf')).fit(X_b01_scaledWithin_H0_train, Y_b01_scaledWithin_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl_h0.score(X_b01_scaledWithin_H0_test, Y_b01_scaledWithin_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H0_test,\n",
    "           y_pred = clf_pl_h0.predict(X_b01_scaledWithin_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H0_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "639574ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.475\n",
      "Confusion-Matrix:\n",
      " [[104  99]\n",
      " [111  86]] \n",
      " \n",
      "True Negative:  104 \n",
      "True Positive 86 \n",
      "False Negative 111 \n",
      "False Positive 99\n",
      "\n",
      "TPR: 0.4365482233502538 \n",
      "TNR:  0.5123152709359606\n",
      "\n",
      "Accuracy: 0.475\n",
      "F1 (micro): 0.47500000000000003\n",
      "F1 (macro): 0.47393471780355223\n"
     ]
    }
   ],
   "source": [
    "# RBF - H1 - scaledWithin\n",
    "clf_pl_rbf = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='rbf')).fit(X_b01_scaledWithin_H1_train, Y_b01_scaledWithin_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl_rbf.score(X_b01_scaledWithin_H1_test, Y_b01_scaledWithin_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H1_test,\n",
    "           y_pred = clf_pl_rbf.predict(X_b01_scaledWithin_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H1_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343bb3f8",
   "metadata": {},
   "source": [
    "##### SVM (Persistent Landscapes - scaledBetween)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f786ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.5375\n",
      "Confusion-Matrix:\n",
      " [[112  90]\n",
      " [ 95 103]] \n",
      " \n",
      "True Negative:  112 \n",
      "True Positive 103 \n",
      "False Negative 95 \n",
      "False Positive 90\n",
      "\n",
      "TPR: 0.5202020202020202 \n",
      "TNR:  0.5544554455445545\n",
      "\n",
      "Accuracy: 0.5375\n",
      "F1 (micro): 0.5375\n",
      "F1 (macro): 0.5372657407812705\n"
     ]
    }
   ],
   "source": [
    "# Linear - H0 - scaledBetween\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_b01_scaledBetween_H0_train, Y_b01_scaledBetween_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_scaledBetween_H0_test, Y_b01_scaledBetween_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H0_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledBetween_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H0_scaledBetween.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d2556a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.545\n",
      "Confusion-Matrix:\n",
      " [[114 100]\n",
      " [ 82 104]] \n",
      " \n",
      "True Negative:  114 \n",
      "True Positive 104 \n",
      "False Negative 82 \n",
      "False Positive 100\n",
      "\n",
      "TPR: 0.5591397849462365 \n",
      "TNR:  0.5327102803738317\n",
      "\n",
      "Accuracy: 0.545\n",
      "F1 (micro): 0.545\n",
      "F1 (macro): 0.5447154471544715\n"
     ]
    }
   ],
   "source": [
    "# Linear - H1 - scaledBetween\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_b01_scaledBetween_H1_train, Y_b01_scaledBetween_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_scaledBetween_H1_test, Y_b01_scaledBetween_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H1_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledBetween_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H1_scaledBetween.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0756a04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.5375\n",
      "Confusion-Matrix:\n",
      " [[142  60]\n",
      " [125  73]] \n",
      " \n",
      "True Negative:  142 \n",
      "True Positive 73 \n",
      "False Negative 125 \n",
      "False Positive 60\n",
      "\n",
      "TPR: 0.3686868686868687 \n",
      "TNR:  0.7029702970297029\n",
      "\n",
      "Accuracy: 0.5375\n",
      "F1 (micro): 0.5375\n",
      "F1 (macro): 0.5233156616571866\n"
     ]
    }
   ],
   "source": [
    "# RBF - H0 - scaledBetween\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_b01_scaledBetween_H0_train, Y_b01_scaledBetween_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_scaledBetween_H0_test, Y_b01_scaledBetween_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H0_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledBetween_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H0_scaledBetween.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b07eef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.54\n",
      "Confusion-Matrix:\n",
      " [[124  90]\n",
      " [ 94  92]] \n",
      " \n",
      "True Negative:  124 \n",
      "True Positive 92 \n",
      "False Negative 94 \n",
      "False Positive 90\n",
      "\n",
      "TPR: 0.4946236559139785 \n",
      "TNR:  0.5794392523364486\n",
      "\n",
      "Accuracy: 0.54\n",
      "F1 (micro): 0.54\n",
      "F1 (macro): 0.537037037037037\n"
     ]
    }
   ],
   "source": [
    "# RBF - H1 - scaledBetween\n",
    "clf_pl_rbf = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_b01_scaledBetween_H1_train, Y_b01_scaledBetween_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl_rbf.score(X_b01_scaledBetween_H1_test, Y_b01_scaledBetween_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H1_test,\n",
    "           y_pred = clf_pl_rbf.predict(X_b01_scaledBetween_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H1_scaledBetween.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc70f402",
   "metadata": {},
   "source": [
    "##### SVM (Persistent Landscapes - unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f4c4135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.5025\n",
      "Confusion-Matrix:\n",
      " [[106  91]\n",
      " [108  95]] \n",
      " \n",
      "True Negative:  106 \n",
      "True Positive 95 \n",
      "False Negative 108 \n",
      "False Positive 91\n",
      "\n",
      "TPR: 0.46798029556650245 \n",
      "TNR:  0.5380710659898477\n",
      "\n",
      "Accuracy: 0.5025\n",
      "F1 (micro): 0.5025\n",
      "F1 (macro): 0.5021234808824173\n"
     ]
    }
   ],
   "source": [
    "# Linear - H0 - unscaled\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_b01_unscaled_H0_train, Y_b01_unscaled_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_unscaled_H0_test, Y_b01_unscaled_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_unscaled_H0_test,\n",
    "           y_pred = clf_pl.predict(X_b01_unscaled_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H0_unscaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec616cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.5275\n",
      "Confusion-Matrix:\n",
      " [[104 100]\n",
      " [ 89 107]] \n",
      " \n",
      "True Negative:  104 \n",
      "True Positive 107 \n",
      "False Negative 89 \n",
      "False Positive 100\n",
      "\n",
      "TPR: 0.5459183673469388 \n",
      "TNR:  0.5098039215686274\n",
      "\n",
      "Accuracy: 0.5275\n",
      "F1 (micro): 0.5275\n",
      "F1 (macro): 0.5274734203798963\n"
     ]
    }
   ],
   "source": [
    "# Linear - H1 - unscaled\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_b01_unscaled_H1_train, Y_b01_unscaled_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_unscaled_H1_test, Y_b01_unscaled_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_unscaled_H1_test,\n",
    "           y_pred = clf_pl.predict(X_b01_unscaled_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H1_unscaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ad264de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.5525\n",
      "Confusion-Matrix:\n",
      " [[153  44]\n",
      " [135  68]] \n",
      " \n",
      "True Negative:  153 \n",
      "True Positive 68 \n",
      "False Negative 135 \n",
      "False Positive 44\n",
      "\n",
      "TPR: 0.33497536945812806 \n",
      "TNR:  0.7766497461928934\n",
      "\n",
      "Accuracy: 0.5525\n",
      "F1 (micro): 0.5525\n",
      "F1 (macro): 0.5313369333987891\n"
     ]
    }
   ],
   "source": [
    "# RBF - H0 - unscaled\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_b01_unscaled_H0_train, Y_b01_unscaled_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_unscaled_H0_test, Y_b01_unscaled_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_unscaled_H0_test,\n",
    "           y_pred = clf_pl.predict(X_b01_unscaled_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H0_unscaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5123f51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.5375\n",
      "Confusion-Matrix:\n",
      " [[121  83]\n",
      " [102  94]] \n",
      " \n",
      "True Negative:  121 \n",
      "True Positive 94 \n",
      "False Negative 102 \n",
      "False Positive 83\n",
      "\n",
      "TPR: 0.47959183673469385 \n",
      "TNR:  0.5931372549019608\n",
      "\n",
      "Accuracy: 0.5375\n",
      "F1 (micro): 0.5375\n",
      "F1 (macro): 0.5353830892001683\n"
     ]
    }
   ],
   "source": [
    "# RBF - H1 - unscaled\n",
    "clf_pl_rbf = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_b01_unscaled_H1_train, Y_b01_unscaled_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl_rbf.score(X_b01_unscaled_H1_test, Y_b01_unscaled_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_unscaled_H1_test,\n",
    "           y_pred = clf_pl_rbf.predict(X_b01_unscaled_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H1_unscaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368fbc18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
