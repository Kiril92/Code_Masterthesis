{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28f5774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 13:42:55.659991: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-16 13:42:55.660022: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-16 13:42:56.880375: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-16 13:42:56.880408: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-16 13:42:56.880428: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (8141ff0cdda3): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x7f51b14be8c0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 13:42:56.880668: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import shape\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "import random\n",
    "import math\n",
    "import dill\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "# from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from random import seed\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import device\n",
    "\n",
    "# Tensorflow soll auf CPU und nicht auf der GPU laufen\n",
    "device(\"cpu:0\")\n",
    "\n",
    "# f√ºr GPU:\n",
    "# tf.device(\"gpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cfebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../../_functions/functions.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3c67a",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90cb3b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 8]), array([178, 174]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data that was saved on this system\n",
    "\n",
    "raw_data = load_file(file = \"../data/raw_data/raw_images_and_labels.pkl\")\n",
    "X = raw_data[0]\n",
    "y = raw_data[1]\n",
    "\n",
    "# Factorize into dichotomous variable\n",
    "Y = pd.factorize(y)[0]\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d954d8",
   "metadata": {},
   "source": [
    "### Load Persistences Landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d4eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_folderpath = \"../data/persistence_landscapes_averages/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bba26de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/persistence_landscapes_averages/avgPL_bucket01_H0_scaledWithin_2022-09-16.pkl\n",
      "../data/persistence_landscapes_averages/avgPL_bucket01_H1_scaledWithin_2022-09-16.pkl\n",
      "../data/persistence_landscapes_averages/avgPL_bucket01_H0_scaledBetween_2022-09-16.pkl\n",
      "../data/persistence_landscapes_averages/avgPL_bucket01_H1_scaledBetween_2022-09-16.pkl\n",
      "../data/persistence_landscapes_averages/avgPL_bucket01_H0_unscaled_2022-09-16.pkl\n",
      "../data/persistence_landscapes_averages/avgPL_bucket01_H1_unscaled_2022-09-16.pkl\n"
     ]
    }
   ],
   "source": [
    "# Eingelesenen Dateien\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H0_scaledWithin*.pkl\")[-1])\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H1_scaledWithin*.pkl\")[-1])\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H0_scaledBetween*.pkl\")[-1])\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H1_scaledBetween*.pkl\")[-1])\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H0_unscaled*.pkl\")[-1])\n",
    "print(glob.glob(pl_folderpath + \"avgPL_bucket01_H1_unscaled*.pkl\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f815523",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgPL_bucket01_H0_scaledWithin = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H0_scaledWithin*.pkl\")[-1])\n",
    "avgPL_bucket01_H1_scaledWithin = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H1_scaledWithin*.pkl\")[-1])\n",
    "\n",
    "avgPL_bucket01_H0_scaledBetween = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H0_scaledBetween*.pkl\")[-1])\n",
    "avgPL_bucket01_H1_scaledBetween = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H1_scaledBetween*.pkl\")[-1])\n",
    "\n",
    "avgPL_bucket01_H0_unscaled = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H0_unscaled*.pkl\")[-1])\n",
    "avgPL_bucket01_H1_unscaled = load_file(file = glob.glob(pl_folderpath + \"avgPL_bucket01_H1_unscaled*.pkl\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a06ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter for persistence landscapes\n",
    "pl_resolution = 250\n",
    "pl_num_landscapes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989417d2",
   "metadata": {},
   "source": [
    "### Train-Test-Splits Persistence Landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e20091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_samples = len(avgPL_bucket01_H0_scaledBetween)\n",
    "relevant_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa49d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket01 scaledBetween\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledBetween_H0_train, X_b01_scaledBetween_H0_test, Y_b01_scaledBetween_H0_train, Y_b01_scaledBetween_H0_test = train_test_split(avgPL_bucket01_H0_scaledBetween,\n",
    "                                                                                                                                        Y,\n",
    "                                                                                                                                        test_size=0.2)\n",
    "\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledBetween_H1_train, X_b01_scaledBetween_H1_test, Y_b01_scaledBetween_H1_train, Y_b01_scaledBetween_H1_test = train_test_split(avgPL_bucket01_H1_scaledBetween,\n",
    "                                                                                                                                        Y,\n",
    "                                                                                                                                        test_size=0.2)\n",
    "\n",
    "# Bucket01 scaledWithin\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledWithin_H0_train, X_b01_scaledWithin_H0_test, Y_b01_scaledWithin_H0_train, Y_b01_scaledWithin_H0_test = train_test_split(avgPL_bucket01_H0_scaledWithin,\n",
    "                                                                                                                                    Y,\n",
    "                                                                                                                                    test_size=0.2)\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_scaledWithin_H1_train, X_b01_scaledWithin_H1_test, Y_b01_scaledWithin_H1_train, Y_b01_scaledWithin_H1_test = train_test_split(avgPL_bucket01_H1_scaledWithin,\n",
    "                                                                                                                                    Y,\n",
    "                                                                                                                                    test_size=0.2)\n",
    "\n",
    "# Bucket01 Unscaled\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_unscaled_H0_train, X_b01_unscaled_H0_test, Y_b01_unscaled_H0_train, Y_b01_unscaled_H0_test = train_test_split(avgPL_bucket01_H0_unscaled,\n",
    "                                                                                                                    Y,\n",
    "                                                                                                                    test_size=0.2)\n",
    "seed(999)\n",
    "# Train-Test-Split \n",
    "X_b01_unscaled_H1_train, X_b01_unscaled_H1_test, Y_b01_unscaled_H1_train, Y_b01_unscaled_H1_test = train_test_split(avgPL_bucket01_H1_unscaled,\n",
    "                                                                                                                    Y,\n",
    "                                                                                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f34a2",
   "metadata": {},
   "source": [
    "# Machine Learning Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c7971",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c467efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb81d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath_results = \"../results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f516e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split with data in vector format\n",
    "image_vector_size = 8*8\n",
    "\n",
    "X_raw_train, X_raw_test, y_raw_train, y_raw_test = train_test_split(X.reshape(len(X), image_vector_size),\n",
    "                                                                    np.asarray(y),\n",
    "                                                                    test_size = 0.3,\n",
    "                                                                    random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e7823",
   "metadata": {},
   "source": [
    "##### SVM (raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bd44915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on raw data: 1.0\n",
      "Confusion-Matrix:\n",
      " [[49  0]\n",
      " [ 0 57]] \n",
      " \n",
      "True Negative:  49 \n",
      "True Positive 57 \n",
      "False Negative 0 \n",
      "False Positive 0\n",
      "\n",
      "TPR: 1.0 \n",
      "TNR:  1.0\n",
      "\n",
      "Accuracy: 1.0\n",
      "F1 (micro): 1.0\n",
      "F1 (macro): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Linear - Rawdata\n",
    "clf = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_raw_train, y_raw_train.ravel())\n",
    "\n",
    "print(\"Accuracy SVM on raw data: \" + str(clf.score(X_raw_test, y_raw_test))[:10])\n",
    "\n",
    "evaluation(y_test = y_raw_test,\n",
    "           y_pred = clf.predict(X_raw_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_rawdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b85ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on raw data: 1.0\n",
      "Confusion-Matrix:\n",
      " [[49  0]\n",
      " [ 0 57]] \n",
      " \n",
      "True Negative:  49 \n",
      "True Positive 57 \n",
      "False Negative 0 \n",
      "False Positive 0\n",
      "\n",
      "TPR: 1.0 \n",
      "TNR:  1.0\n",
      "\n",
      "Accuracy: 1.0\n",
      "F1 (micro): 1.0\n",
      "F1 (macro): 1.0\n"
     ]
    }
   ],
   "source": [
    "# RBF - Rawdata\n",
    "clf = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_raw_train, y_raw_train.ravel())\n",
    "\n",
    "print(\"Accuracy SVM on raw data: \" + str(clf.score(X_raw_test, y_raw_test))[:10])\n",
    "\n",
    "evaluation(y_test = y_raw_test,\n",
    "           y_pred = clf.predict(X_raw_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_rawdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf41392",
   "metadata": {},
   "source": [
    "##### SVM (Persistent Landscapes - scaledWithin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b260123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.53521126\n",
      "Confusion-Matrix:\n",
      " [[22  8]\n",
      " [25 16]] \n",
      " \n",
      "True Negative:  22 \n",
      "True Positive 16 \n",
      "False Negative 25 \n",
      "False Positive 8\n",
      "\n",
      "TPR: 0.3902439024390244 \n",
      "TNR:  0.7333333333333333\n",
      "\n",
      "Accuracy: 0.5352112676056338\n",
      "F1 (micro): 0.5352112676056338\n",
      "F1 (macro): 0.5318681318681319\n"
     ]
    }
   ],
   "source": [
    "# Linear - H0 - scaledWithin\n",
    "clf_pl_h0 = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='linear')).fit(X_b01_scaledWithin_H0_train, Y_b01_scaledWithin_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl_h0.score(X_b01_scaledWithin_H0_test, Y_b01_scaledWithin_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H0_test,\n",
    "           y_pred = clf_pl_h0.predict(X_b01_scaledWithin_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H0_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "116d83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.52112676\n",
      "Confusion-Matrix:\n",
      " [[18 19]\n",
      " [15 19]] \n",
      " \n",
      "True Negative:  18 \n",
      "True Positive 19 \n",
      "False Negative 15 \n",
      "False Positive 19\n",
      "\n",
      "TPR: 0.5588235294117647 \n",
      "TNR:  0.4864864864864865\n",
      "\n",
      "Accuracy: 0.5211267605633803\n",
      "F1 (micro): 0.5211267605633803\n",
      "F1 (macro): 0.5210317460317461\n"
     ]
    }
   ],
   "source": [
    "# Linear - H1 - scaledWithin\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='linear')).fit(X_b01_scaledWithin_H1_train, Y_b01_scaledWithin_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl.score(X_b01_scaledWithin_H1_test, Y_b01_scaledWithin_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H1_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledWithin_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H1_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6d94b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.59154929\n",
      "Confusion-Matrix:\n",
      " [[19 11]\n",
      " [18 23]] \n",
      " \n",
      "True Negative:  19 \n",
      "True Positive 23 \n",
      "False Negative 18 \n",
      "False Positive 11\n",
      "\n",
      "TPR: 0.5609756097560976 \n",
      "TNR:  0.6333333333333333\n",
      "\n",
      "Accuracy: 0.5915492957746479\n",
      "F1 (micro): 0.5915492957746479\n",
      "F1 (macro): 0.5902487562189054\n"
     ]
    }
   ],
   "source": [
    "# RBF - H0 - scaledWithin\n",
    "clf_pl_h0 = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='rbf')).fit(X_b01_scaledWithin_H0_train, Y_b01_scaledWithin_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl_h0.score(X_b01_scaledWithin_H0_test, Y_b01_scaledWithin_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H0_test,\n",
    "           y_pred = clf_pl_h0.predict(X_b01_scaledWithin_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H0_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "639574ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM on peristence landscapes (scaled within sample): 0.54929577\n",
      "Confusion-Matrix:\n",
      " [[12 25]\n",
      " [ 7 27]] \n",
      " \n",
      "True Negative:  12 \n",
      "True Positive 27 \n",
      "False Negative 7 \n",
      "False Positive 25\n",
      "\n",
      "TPR: 0.7941176470588235 \n",
      "TNR:  0.32432432432432434\n",
      "\n",
      "Accuracy: 0.5492957746478874\n",
      "F1 (micro): 0.5492957746478874\n",
      "F1 (macro): 0.5282392026578073\n"
     ]
    }
   ],
   "source": [
    "# RBF - H1 - scaledWithin\n",
    "clf_pl_rbf = make_pipeline(StandardScaler(), \n",
    "                       SVC(kernel='rbf')).fit(X_b01_scaledWithin_H1_train, Y_b01_scaledWithin_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM on peristence landscapes (scaled within sample): \" + str(clf_pl_rbf.score(X_b01_scaledWithin_H1_test, Y_b01_scaledWithin_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledWithin_H1_test,\n",
    "           y_pred = clf_pl_rbf.predict(X_b01_scaledWithin_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H1_scaledWithin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343bb3f8",
   "metadata": {},
   "source": [
    "##### SVM (Persistent Landscapes - scaledBetween)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f786ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.54929577\n",
      "Confusion-Matrix:\n",
      " [[23 14]\n",
      " [18 16]] \n",
      " \n",
      "True Negative:  23 \n",
      "True Positive 16 \n",
      "False Negative 18 \n",
      "False Positive 14\n",
      "\n",
      "TPR: 0.47058823529411764 \n",
      "TNR:  0.6216216216216216\n",
      "\n",
      "Accuracy: 0.5492957746478874\n",
      "F1 (micro): 0.5492957746478874\n",
      "F1 (macro): 0.5448717948717949\n"
     ]
    }
   ],
   "source": [
    "# Linear - H0 - scaledBetween\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_b01_scaledBetween_H0_train, Y_b01_scaledBetween_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_scaledBetween_H0_test, Y_b01_scaledBetween_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H0_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledBetween_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H0_scaledBetween.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d2556a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.50704225\n",
      "Confusion-Matrix:\n",
      " [[22 12]\n",
      " [23 14]] \n",
      " \n",
      "True Negative:  22 \n",
      "True Positive 14 \n",
      "False Negative 23 \n",
      "False Positive 12\n",
      "\n",
      "TPR: 0.3783783783783784 \n",
      "TNR:  0.6470588235294118\n",
      "\n",
      "Accuracy: 0.5070422535211268\n",
      "F1 (micro): 0.5070422535211268\n",
      "F1 (macro): 0.5007032348804501\n"
     ]
    }
   ],
   "source": [
    "# Linear - H1 - scaledBetween\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_b01_scaledBetween_H1_train, Y_b01_scaledBetween_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_scaledBetween_H1_test, Y_b01_scaledBetween_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H1_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledBetween_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H1_scaledBetween.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0756a04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.57746478\n",
      "Confusion-Matrix:\n",
      " [[17 20]\n",
      " [10 24]] \n",
      " \n",
      "True Negative:  17 \n",
      "True Positive 24 \n",
      "False Negative 10 \n",
      "False Positive 20\n",
      "\n",
      "TPR: 0.7058823529411765 \n",
      "TNR:  0.4594594594594595\n",
      "\n",
      "Accuracy: 0.5774647887323944\n",
      "F1 (micro): 0.5774647887323944\n",
      "F1 (macro): 0.5733173076923077\n"
     ]
    }
   ],
   "source": [
    "# RBF - H0 - scaledBetween\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_b01_scaledBetween_H0_train, Y_b01_scaledBetween_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_scaledBetween_H0_test, Y_b01_scaledBetween_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H0_test,\n",
    "           y_pred = clf_pl.predict(X_b01_scaledBetween_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H0_scaledBetween.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b07eef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.57746478\n",
      "Confusion-Matrix:\n",
      " [[22 12]\n",
      " [18 19]] \n",
      " \n",
      "True Negative:  22 \n",
      "True Positive 19 \n",
      "False Negative 18 \n",
      "False Positive 12\n",
      "\n",
      "TPR: 0.5135135135135135 \n",
      "TNR:  0.6470588235294118\n",
      "\n",
      "Accuracy: 0.5774647887323944\n",
      "F1 (micro): 0.5774647887323944\n",
      "F1 (macro): 0.5767090620031796\n"
     ]
    }
   ],
   "source": [
    "# RBF - H1 - scaledBetween\n",
    "clf_pl_rbf = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_b01_scaledBetween_H1_train, Y_b01_scaledBetween_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl_rbf.score(X_b01_scaledBetween_H1_test, Y_b01_scaledBetween_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_scaledBetween_H1_test,\n",
    "           y_pred = clf_pl_rbf.predict(X_b01_scaledBetween_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H1_scaledBetween.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc70f402",
   "metadata": {},
   "source": [
    "##### SVM (Persistent Landscapes - unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f4c4135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.64788732\n",
      "Confusion-Matrix:\n",
      " [[17 16]\n",
      " [ 9 29]] \n",
      " \n",
      "True Negative:  17 \n",
      "True Positive 29 \n",
      "False Negative 9 \n",
      "False Positive 16\n",
      "\n",
      "TPR: 0.7631578947368421 \n",
      "TNR:  0.5151515151515151\n",
      "\n",
      "Accuracy: 0.647887323943662\n",
      "F1 (micro): 0.647887323943662\n",
      "F1 (macro): 0.6375331835817848\n"
     ]
    }
   ],
   "source": [
    "# Linear - H0 - unscaled\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_b01_unscaled_H0_train, Y_b01_unscaled_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_unscaled_H0_test, Y_b01_unscaled_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_unscaled_H0_test,\n",
    "           y_pred = clf_pl.predict(X_b01_unscaled_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H0_unscaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec616cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.52112676\n",
      "Confusion-Matrix:\n",
      " [[15 24]\n",
      " [10 22]] \n",
      " \n",
      "True Negative:  15 \n",
      "True Positive 22 \n",
      "False Negative 10 \n",
      "False Positive 24\n",
      "\n",
      "TPR: 0.6875 \n",
      "TNR:  0.38461538461538464\n",
      "\n",
      "Accuracy: 0.5211267605633803\n",
      "F1 (micro): 0.5211267605633803\n",
      "F1 (macro): 0.5164262820512822\n"
     ]
    }
   ],
   "source": [
    "# Linear - H1 - unscaled\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='linear')).fit(X_b01_unscaled_H1_train, Y_b01_unscaled_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_unscaled_H1_test, Y_b01_unscaled_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_unscaled_H1_test,\n",
    "           y_pred = clf_pl.predict(X_b01_unscaled_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_linear_H1_unscaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ad264de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.56338028\n",
      "Confusion-Matrix:\n",
      " [[15 18]\n",
      " [13 25]] \n",
      " \n",
      "True Negative:  15 \n",
      "True Positive 25 \n",
      "False Negative 13 \n",
      "False Positive 18\n",
      "\n",
      "TPR: 0.6578947368421053 \n",
      "TNR:  0.45454545454545453\n",
      "\n",
      "Accuracy: 0.5633802816901409\n",
      "F1 (micro): 0.5633802816901409\n",
      "F1 (macro): 0.5545436146529042\n"
     ]
    }
   ],
   "source": [
    "# RBF - H0 - unscaled\n",
    "clf_pl = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_b01_unscaled_H0_train, Y_b01_unscaled_H0_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl.score(X_b01_unscaled_H0_test, Y_b01_unscaled_H0_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_unscaled_H0_test,\n",
    "           y_pred = clf_pl.predict(X_b01_unscaled_H0_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H0_unscaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5123f51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM : 0.56338028\n",
      "Confusion-Matrix:\n",
      " [[12 27]\n",
      " [ 4 28]] \n",
      " \n",
      "True Negative:  12 \n",
      "True Positive 28 \n",
      "False Negative 4 \n",
      "False Positive 27\n",
      "\n",
      "TPR: 0.875 \n",
      "TNR:  0.3076923076923077\n",
      "\n",
      "Accuracy: 0.5633802816901409\n",
      "F1 (micro): 0.5633802816901409\n",
      "F1 (macro): 0.5400208986415883\n"
     ]
    }
   ],
   "source": [
    "# RBF - H1 - unscaled\n",
    "clf_pl_rbf = make_pipeline(StandardScaler(), \n",
    "                    SVC(kernel='rbf')).fit(X_b01_unscaled_H1_train, Y_b01_unscaled_H1_train)\n",
    "\n",
    "print(\"Accuracy SVM : \" + str(clf_pl_rbf.score(X_b01_unscaled_H1_test, Y_b01_unscaled_H1_test))[:10])\n",
    "\n",
    "evaluation(y_test = Y_b01_unscaled_H1_test,\n",
    "           y_pred = clf_pl_rbf.predict(X_b01_unscaled_H1_test),\n",
    "           filename_csv = folderpath_results + \"svm_rbf_H1_unscaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368fbc18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
